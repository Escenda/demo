# GLM-4.1V-9B-Thinking チャットボット

GLM-4.1V-9B-Thinkingモデルを使用した対話型の画像記述チャットボットです。画像とテキストの両方を理解し、自然な会話を行うことができます。

## 機能

- ターン制の対話型チャット
- 画像の読み込み（URLまたはローカルファイル）
- 会話履歴の管理
- 画像に関する質問応答
- マルチモーダル理解（画像＋テキスト）

## セットアップ

1. 必要なパッケージをインストール：
```bash
pip install -r requirements.txt
```

2. プログラムを実行：
```bash
python main.py
```

## 使い方

### 基本的な使い方

プログラムを起動すると、対話型のプロンプトが表示されます：
```
あなた: こんにちは
GLM-4V: こんにちは！何かお手伝いできることはありますか？
```

### コマンド一覧

- `/help` - ヘルプを表示
- `/image <パスまたはURL>` - 画像を読み込む
- `/clear` - 会話履歴をクリア
- `/clearimage` - 現在の画像をクリア
- `/exit` または `/quit` - プログラムを終了

### 使用例

1. **画像を読み込んで質問する**：
```
あなた: /image https://example.com/image.jpg
画像を読み込みました: https://example.com/image.jpg

あなた: この画像には何が写っていますか？
GLM-4V: [画像の内容についての説明]
```

2. **ローカル画像を使用**：
```
あなた: /image ./my_photo.png
画像を読み込みました: ./my_photo.png

あなた: この写真の雰囲気はどうですか？
GLM-4V: [写真の雰囲気についての説明]
```

3. **会話を続ける**：
```
あなた: もっと詳しく教えてください
GLM-4V: [より詳細な説明]
```

## 注意事項

- 大きなモデル（9B）を使用するため、初回起動時にはモデルのダウンロードに時間がかかります
- GPUメモリが十分にあることを確認してください（推奨: 16GB以上）
- `device_map="auto"`により、利用可能なデバイスに自動的に配置されます

## 必要な環境

- Python 3.8以上
- CUDA対応GPU（推奨）
- 十分なRAM（推奨: 32GB以上）

## トラブルシューティング

### ImportError が発生する場合
transformersのバージョンが古い可能性があります：
```bash
pip install --upgrade transformers>=4.52.0
```

### メモリ不足の場合
- `torch_dtype=torch.float16`に変更してメモリ使用量を削減できます
- `device_map="auto"`の代わりに特定のデバイスを指定することもできます